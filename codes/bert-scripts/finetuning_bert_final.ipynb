{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3c48fe-a957-4531-9cdf-e3b84b914245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/chowdam.v/kumar/inlp_project/inlp_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (AutoModelForTokenClassification, AutoTokenizer,\n",
    "                          DataCollatorForTokenClassification,\n",
    "                          EarlyStoppingCallback, Trainer, TrainingArguments,\n",
    "                          set_seed)\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac315f5-b9f3-4f82-a656-f7a55b4e7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('json', data_files={'train': \"fial_jsons/train_all.json\",\n",
    "                                              'validation': 'fial_jsons/val_all.json'})\n",
    "class_names = ['ARGM-PRP',\n",
    " 'ARGM-NEG',\n",
    " 'NAA',\n",
    " 'ARGA',\n",
    " 'ARGM-EXT',\n",
    " 'ARGM-DIS',\n",
    " 'ARG0',\n",
    " 'ARGM-ADV',\n",
    " 'ARG2-ATR',\n",
    " 'ARG1',\n",
    " 'ARG3',\n",
    " 'ARGM-DIR',\n",
    " 'ARGM-LOC',\n",
    " 'ARG2-LOC',\n",
    " 'ARG0-GOL',\n",
    " 'Predicate',\n",
    " 'NAH',\n",
    " 'ARG2-SOU',\n",
    " 'ARGM-MNS',\n",
    " 'ARGM-CAU',\n",
    " 'ARGM-PRX',\n",
    " 'ARGM-TMP',\n",
    " 'ARGM-MNR',\n",
    " 'ARG2',\n",
    " 'ARG2-GOL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c6499",
   "metadata": {},
   "source": [
    "# Finetuning bert based models\n",
    "Instruction: Run the following cells seperately for different models i.e \"ai4bharat/indic-bert\", \"google-bert/bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab666732-e8a9-4598-a63e-477859d1bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google-bert/bert-base-multilingual-cased\"\n",
    "# model_name = \"ai4bharat/indic-bert\"\n",
    "output_dir = \"output\"\n",
    "do_train = False\n",
    "do_predict = False\n",
    "label_all_tokens = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f5530c-1377-4cdb-b631-9c8977db35e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11892/11892 [00:03<00:00, 3751.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training Dataset: 11892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2548/2548 [00:00<00:00, 3911.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of Validation Dataset: 2548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3348' max='7440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3348/7440 44:33 < 54:29, 1.25 it/s, Epoch 9/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.176640</td>\n",
       "      <td>0.171081</td>\n",
       "      <td>0.135584</td>\n",
       "      <td>0.138356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.566000</td>\n",
       "      <td>1.046580</td>\n",
       "      <td>0.372284</td>\n",
       "      <td>0.210500</td>\n",
       "      <td>0.225434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.041100</td>\n",
       "      <td>1.016270</td>\n",
       "      <td>0.370802</td>\n",
       "      <td>0.251212</td>\n",
       "      <td>0.272658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.041100</td>\n",
       "      <td>1.009658</td>\n",
       "      <td>0.328788</td>\n",
       "      <td>0.295133</td>\n",
       "      <td>0.300102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.928900</td>\n",
       "      <td>1.016793</td>\n",
       "      <td>0.405713</td>\n",
       "      <td>0.304734</td>\n",
       "      <td>0.313190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.826900</td>\n",
       "      <td>1.037390</td>\n",
       "      <td>0.386748</td>\n",
       "      <td>0.313435</td>\n",
       "      <td>0.317281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.750200</td>\n",
       "      <td>1.088175</td>\n",
       "      <td>0.388243</td>\n",
       "      <td>0.323283</td>\n",
       "      <td>0.321584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.750200</td>\n",
       "      <td>1.134245</td>\n",
       "      <td>0.391525</td>\n",
       "      <td>0.358146</td>\n",
       "      <td>0.347632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.670900</td>\n",
       "      <td>1.179428</td>\n",
       "      <td>0.398527</td>\n",
       "      <td>0.333578</td>\n",
       "      <td>0.340491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"words\"], truncation='longest_first', is_split_into_words=True, max_length=512)\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"srl\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for (p, l) in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                true_predictions.append(p)\n",
    "                true_labels.append(l)\n",
    "                \n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels,true_predictions, average='macro') ,\n",
    "        \"recall\": recall_score(true_labels,true_predictions, average='macro'),\n",
    "        \"f1\": f1_score(true_labels,true_predictions, average='macro'),\n",
    "    }\n",
    "\n",
    "label_list = class_names\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "if do_train:\n",
    "\n",
    "    train_dataset = dataset[\"train\"].map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=dataset[\"train\"].column_names,\n",
    "    )\n",
    "    print(f\"Length of Training Dataset: {len(train_dataset)}\")\n",
    "\n",
    "    validation_dataset = dataset[\"validation\"].map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=dataset[\"validation\"].column_names,\n",
    "    )\n",
    "    print(f\"Lenght of Validation Dataset: {len(validation_dataset)}\")\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{output_dir}/{model_name}\",\n",
    "        save_total_limit=1,\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=20,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        weight_decay=0.0,\n",
    "        fp16=True,\n",
    "        warmup_ratio=0.1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False\n",
    "    )\n",
    "\n",
    "    earlystoppingcallback = EarlyStoppingCallback(early_stopping_patience=5)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=validation_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[earlystoppingcallback]\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a46ee122-5fef-4ccb-a12e-aba8163e3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best model checkpoints\n",
    "trainer.save_model(\"bert-multilingual-cased-lat-finetuned-srl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d4c44-f241-47b0-91a6-ec2fa0897bde",
   "metadata": {},
   "source": [
    "# Testing language wise for different cases\n",
    "1. Argument identification\n",
    "2. Argument classification\n",
    "3. Overall\n",
    "\n",
    "use `compute_metrics_argument_identification` as compute-metric argument for argument identification \n",
    "\n",
    "use `compute_metrics_argument_classification` as compute-metric argument for argument classification \n",
    "\n",
    "use `compute_metrics_all` as compute-metric argument for overall performance\n",
    "\n",
    "Instuction: Run the following cells multiple times for the above 3 performances by changing `compute-metric` argument when calling trainer api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b3133c-c60f-4bd8-a02f-8dd6642590ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_argument_identification(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for (p, l) in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                if l not in [15,16]:\n",
    "                        true_labels.append(0 if l == 2 else 1)\n",
    "                        true_predictions.append(0 if p == 2 else 1)\n",
    "                \n",
    "    return {\n",
    "        \"precision-macro\": precision_score(true_labels,true_predictions, average='macro') ,\n",
    "        \"recall-macro\": recall_score(true_labels,true_predictions, average='macro'),\n",
    "        \"f1-macro\": f1_score(true_labels,true_predictions, average='macro'),\n",
    "        \"precision-weighted\": precision_score(true_labels,true_predictions, average='weighted') ,\n",
    "        \"recall-weighted\": recall_score(true_labels,true_predictions, average='weighted'),\n",
    "        \"f1-weighted\": f1_score(true_labels,true_predictions, average='weighted'),\n",
    "                            \n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics_argument_classification(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for (p, l) in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                if l not in [15,16]:\n",
    "                    true_predictions.append(p)\n",
    "                    true_labels.append(l)\n",
    "                \n",
    "    return {\n",
    "        \"precision-macro\": precision_score(true_labels,true_predictions, average='macro') ,\n",
    "        \"recall-macro\": recall_score(true_labels,true_predictions, average='macro'),\n",
    "        \"f1-macro\": f1_score(true_labels,true_predictions, average='macro'),\n",
    "        \"precision-weighted\": precision_score(true_labels,true_predictions, average='weighted') ,\n",
    "        \"recall-weighted\": recall_score(true_labels,true_predictions, average='weighted'),\n",
    "        \"f1-weighted\": f1_score(true_labels,true_predictions, average='weighted'),\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics_all(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for (p, l) in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                true_predictions.append(p)\n",
    "                true_labels.append(l)\n",
    "                \n",
    "    return {\n",
    "        \"precision-macro\": precision_score(true_labels,true_predictions, average='macro') ,\n",
    "        \"recall-macro\": recall_score(true_labels,true_predictions, average='macro'),\n",
    "        \"f1-macro\": f1_score(true_labels,true_predictions, average='macro'),\n",
    "        \"precision-weighted\": precision_score(true_labels,true_predictions, average='weighted') ,\n",
    "        \"recall-weighted\": recall_score(true_labels,true_predictions, average='weighted'),\n",
    "        \"f1-weighted\": f1_score(true_labels,true_predictions, average='weighted'),\n",
    "    }\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"words\"], truncation='longest_first', is_split_into_words=True, max_length=512)\n",
    "    print(f\"Label all tokens from tokenize_and_align_labels function {label_all_tokens}\")\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"srl\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f58390a-2967-41b3-8ddc-d9ccf08d61f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- indic-bert-finetuned-srl -------------------------\n",
      "Label all tokens from main function False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for hindi: {'test_loss': 0.8649789690971375, 'test_precision-macro': 0.3970191912584015, 'test_recall-macro': 0.24843825911307707, 'test_f1-macro': 0.2807057564142384, 'test_precision-weighted': 0.7033877970987126, 'test_recall-weighted': 0.7153618336337884, 'test_f1-weighted': 0.7043757453869288, 'test_runtime': 1.7414, 'test_samples_per_second': 366.371, 'test_steps_per_second': 11.485}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for urdu: {'test_loss': 0.8606521487236023, 'test_precision-macro': 0.3820534250223506, 'test_recall-macro': 0.24611217770609306, 'test_f1-macro': 0.2772327284878324, 'test_precision-weighted': 0.6921091341047291, 'test_recall-weighted': 0.7138384086444007, 'test_f1-weighted': 0.6915894495428145, 'test_runtime': 4.0043, 'test_samples_per_second': 159.328, 'test_steps_per_second': 4.995}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for tamil: {'test_loss': 1.1957036256790161, 'test_precision-macro': 0.308755211025052, 'test_recall-macro': 0.16948987970187757, 'test_f1-macro': 0.1899522338500692, 'test_precision-weighted': 0.5855275957332987, 'test_recall-weighted': 0.6037459760023413, 'test_f1-weighted': 0.5827483566091488, 'test_runtime': 1.941, 'test_samples_per_second': 328.697, 'test_steps_per_second': 10.304}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for telugu: {'test_loss': 1.2218786478042603, 'test_precision-macro': 0.2804714022594595, 'test_recall-macro': 0.16461760862065297, 'test_f1-macro': 0.18487954240028429, 'test_precision-weighted': 0.5842227447156424, 'test_recall-weighted': 0.6014800197335964, 'test_f1-weighted': 0.5793397162779664, 'test_runtime': 1.7363, 'test_samples_per_second': 367.443, 'test_steps_per_second': 11.519}\n",
      "---------------- indic-bert-lat-finetuned-srl -------------------------\n",
      "Label all tokens from main function True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for hindi: {'test_loss': 0.9695111513137817, 'test_precision-macro': 0.3796522093417347, 'test_recall-macro': 0.2005207752537422, 'test_f1-macro': 0.22977918137163858, 'test_precision-weighted': 0.6776578708219299, 'test_recall-weighted': 0.6758569299552906, 'test_f1-weighted': 0.6618471008361207, 'test_runtime': 1.7795, 'test_samples_per_second': 358.52, 'test_steps_per_second': 11.239}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for urdu: {'test_loss': 0.9307342767715454, 'test_precision-macro': 0.3643717107941405, 'test_recall-macro': 0.24859044649404569, 'test_f1-macro': 0.28514811790653755, 'test_precision-weighted': 0.6806664924433051, 'test_recall-weighted': 0.6872126947982637, 'test_f1-weighted': 0.6736706333911643, 'test_runtime': 4.2778, 'test_samples_per_second': 149.143, 'test_steps_per_second': 4.675}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for tamil: {'test_loss': 1.3113352060317993, 'test_precision-macro': 0.3089140695961398, 'test_recall-macro': 0.15757126708982672, 'test_f1-macro': 0.18493101223007535, 'test_precision-weighted': 0.5622518493283274, 'test_recall-weighted': 0.5698211462756889, 'test_f1-weighted': 0.5441155519019689, 'test_runtime': 2.0694, 'test_samples_per_second': 308.306, 'test_steps_per_second': 9.665}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for telugu: {'test_loss': 1.3257864713668823, 'test_precision-macro': 0.2763183040881881, 'test_recall-macro': 0.1494943525791851, 'test_f1-macro': 0.1735637500549916, 'test_precision-weighted': 0.5574667397856046, 'test_recall-weighted': 0.5686422957675391, 'test_f1-weighted': 0.5407162523320217, 'test_runtime': 1.8396, 'test_samples_per_second': 346.823, 'test_steps_per_second': 10.872}\n",
      "---------------- bert-multilingual-cased-finetuned-srl -------------------------\n",
      "Label all tokens from main function False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for hindi: {'test_loss': 0.7975223064422607, 'test_precision-macro': 0.36781928753473286, 'test_recall-macro': 0.3212379740234714, 'test_f1-macro': 0.3243661283792209, 'test_precision-weighted': 0.7278269692373353, 'test_recall-weighted': 0.7325521503991759, 'test_f1-weighted': 0.7292267642965696, 'test_runtime': 2.9225, 'test_samples_per_second': 218.304, 'test_steps_per_second': 6.843}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for urdu: {'test_loss': 0.582085132598877, 'test_precision-macro': 0.4552410899012174, 'test_recall-macro': 0.39895659935227235, 'test_f1-macro': 0.4086628383386534, 'test_precision-weighted': 0.8015562478369707, 'test_recall-weighted': 0.806544695481336, 'test_f1-weighted': 0.8031085443057607, 'test_runtime': 2.8038, 'test_samples_per_second': 227.546, 'test_steps_per_second': 7.133}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for tamil: {'test_loss': 1.1070899963378906, 'test_precision-macro': 0.295489053923806, 'test_recall-macro': 0.2346720815334721, 'test_f1-macro': 0.2483453706439215, 'test_precision-weighted': 0.6151124724635257, 'test_recall-weighted': 0.6328163106038436, 'test_f1-weighted': 0.6215929572627091, 'test_runtime': 3.1929, 'test_samples_per_second': 199.815, 'test_steps_per_second': 6.264}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for telugu: {'test_loss': 1.0996220111846924, 'test_precision-macro': 0.28312059328028377, 'test_recall-macro': 0.23602395775867402, 'test_f1-macro': 0.24810021163951732, 'test_precision-weighted': 0.6179542663812712, 'test_recall-weighted': 0.635027133695116, 'test_f1-weighted': 0.6241226039048188, 'test_runtime': 3.433, 'test_samples_per_second': 185.844, 'test_steps_per_second': 5.826}\n",
      "---------------- bert-multilingual-cased-lat-finetuned-srl -------------------------\n",
      "Label all tokens from main function True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for hindi: {'test_loss': 0.9272770881652832, 'test_precision-macro': 0.3792084843164745, 'test_recall-macro': 0.2982529148743553, 'test_f1-macro': 0.3094828878870961, 'test_precision-weighted': 0.6841318934661724, 'test_recall-weighted': 0.690176322418136, 'test_f1-weighted': 0.6849535174389756, 'test_runtime': 2.994, 'test_samples_per_second': 213.094, 'test_steps_per_second': 6.68}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for urdu: {'test_loss': 0.6847628355026245, 'test_precision-macro': 0.43125761214858943, 'test_recall-macro': 0.360243525323777, 'test_f1-macro': 0.3791191403921131, 'test_precision-weighted': 0.7695020069248988, 'test_recall-weighted': 0.7772697583278902, 'test_f1-weighted': 0.7712362823533837, 'test_runtime': 2.8528, 'test_samples_per_second': 223.643, 'test_steps_per_second': 7.011}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for tamil: {'test_loss': 1.2331571578979492, 'test_precision-macro': 0.2744327903318415, 'test_recall-macro': 0.21872827393823877, 'test_f1-macro': 0.23311105086313155, 'test_precision-weighted': 0.5735115182913081, 'test_recall-weighted': 0.5912012003510461, 'test_f1-weighted': 0.5795851141454745, 'test_runtime': 3.2959, 'test_samples_per_second': 193.572, 'test_steps_per_second': 6.068}\n",
      "Length of Test Dataset: 638\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for telugu: {'test_loss': 1.2283591032028198, 'test_precision-macro': 0.28302176382653993, 'test_recall-macro': 0.2270439855315812, 'test_f1-macro': 0.24344856830234443, 'test_precision-weighted': 0.5762767836634966, 'test_recall-weighted': 0.5942475741167641, 'test_f1-weighted': 0.5820895840885354, 'test_runtime': 3.5579, 'test_samples_per_second': 179.321, 'test_steps_per_second': 5.621}\n"
     ]
    }
   ],
   "source": [
    "models = ['indic-bert-finetuned-srl','indic-bert-lat-finetuned-srl','bert-multilingual-cased-finetuned-srl','bert-multilingual-cased-lat-finetuned-srl']\n",
    "for model_name in models:\n",
    "    if 'lat' in model_name:\n",
    "        label_all_tokens = True\n",
    "    else:\n",
    "        label_all_tokens = False\n",
    "    \n",
    "    print(f\"---------------- {model_name} -------------------------\")\n",
    "    print(f\"Label all tokens from main function {label_all_tokens}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "                    output_dir = model_name,\n",
    "                    per_device_eval_batch_size=16,\n",
    "                    fp16=True,\n",
    "                    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics_all,\n",
    "    )\n",
    "    for file in glob.glob(\"fial_jsons/test_*.json\"):\n",
    "        lang = file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]\n",
    "        # print(lang)\n",
    "        dataset = load_dataset('json', data_files={'test': file})\n",
    "    \n",
    "        test_dataset = dataset['test'].map(\n",
    "            tokenize_and_align_labels,\n",
    "            batched=True,\n",
    "            remove_columns=dataset['test'].column_names,\n",
    "        )\n",
    "        print(f\"Length of Test Dataset: {len(test_dataset)}\")\n",
    "        \n",
    "        results = trainer.predict(test_dataset).metrics\n",
    "        print(f\"Results for {lang}: {results}\")\n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0042a97-cad1-4d95-becb-95274cfbd357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
